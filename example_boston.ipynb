{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "from types import SimpleNamespace\n",
    "from typing import Tuple, List\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "    \n",
    "adult = fetch_openml(data_id = 531, data_home='./data_cache')\n",
    "\n",
    "data = adult.data\n",
    "\n",
    "le = LabelEncoder()\n",
    "label = pd.Series(le.fit_transform(adult.target))\n",
    "\n",
    "\n",
    "category_cols = [\"CHAS\"]\n",
    "continuous_cols = [x for x in data.columns if x not in category_cols]\n",
    "\n",
    "for col in category_cols:\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "temp = None\n",
    "for col in category_cols:\n",
    "    oh_values = OneHotEncoder().fit_transform(data[col].values.reshape((-1, 1))).toarray()\n",
    "    new_cols = [col + \"-\" + str(i) for i in range(len(data[col].unique()))]\n",
    "    oh_values = pd.DataFrame(oh_values, columns = new_cols, dtype=np.int8, index=data.index)\n",
    "    if temp is None:\n",
    "        temp = oh_values\n",
    "    else:\n",
    "        temp = temp.merge(oh_values, left_index=True, right_index=True)\n",
    "\n",
    "data = data.merge(temp, left_index=True, right_index=True)\n",
    "data.drop(category_cols, inplace=True, axis=1)\n",
    "\n",
    "category_cols = temp.columns\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data[continuous_cols] = scaler.fit_transform(data[continuous_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "model_hparams = {\n",
    "    \"encoder_dim\" : data.shape[1],\n",
    "    \"predictor_hidden_dim\" : 256,\n",
    "    \"predictor_output_dim\" : 1,\n",
    "    'alpha1' : 0.5,\n",
    "    'alpha2' : 0.5,\n",
    "    'beta' : 0.5,\n",
    "    'K' : 10\n",
    "}\n",
    "data_hparams = {\n",
    "    \"K\" : 10,\n",
    "    \"p_m\" : 0.2\n",
    "}\n",
    "optim_hparams = {\n",
    "    \"lr\" : 0.005\n",
    "}\n",
    "scheduler_hparams = {\n",
    "    'scheduler_gamma' : 0.3,\n",
    "    'scheduler_step_size' : 30\n",
    "}\n",
    "num_categoricals = len(continuous_cols)\n",
    "num_continuous = len(continuous_cols)\n",
    "consistency_loss = nn.MSELoss\n",
    "loss_fn = nn.MSELoss\n",
    "metric =  \"mean_squared_error\"\n",
    "random_seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc.scorer import BaseScorer\n",
    "\n",
    "\n",
    "class MSEScorer(BaseScorer):\n",
    "    def __init__(self, metric: str) -> None:\n",
    "        super().__init__(metric)\n",
    "    \n",
    "    def __call__(self, y, y_hat) -> float:\n",
    "        return self.metric(y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    }
   ],
   "source": [
    "from pl_vime import PLVIME\n",
    "pl_vime = PLVIME(model_hparams, optim_hparams, scheduler_hparams, \n",
    "       num_categoricals, num_continuous, -1,  consistency_loss, loss_fn,\n",
    "       MSEScorer(\"mean_squared_error\"), random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(data, label, train_size = 0.7, random_state=random_seed)\n",
    "\n",
    "X_train, X_unlabeled, y_train, _ = train_test_split(X_train, y_train, train_size = 0.3, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from data_utils import *\n",
    "\n",
    "n_gpus = 1\n",
    "n_jobs = 32\n",
    "max_epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "pretraining_patience = 10\n",
    "early_stopping_patience = 30\n",
    "\n",
    "def fit_model(\n",
    "            model,\n",
    "    ):\n",
    "    \n",
    "    train_ds = VIMESelfDataset(X_train.append(X_unlabeled), data_hparams, continuous_cols, category_cols)\n",
    "    test_ds = VIMESelfDataset(X_valid, data_hparams, continuous_cols, category_cols)\n",
    "    \n",
    "    pl_datamodule = PLDataModule(train_ds, test_ds, batch_size=batch_size, is_regression=True)\n",
    "\n",
    "    model.do_pretraining()\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor= 'val_loss', \n",
    "            mode = 'min',\n",
    "            patience = pretraining_patience,\n",
    "            verbose = False\n",
    "        )\n",
    "    ]\n",
    "    pretraining_path = f'temporary_ckpt_data/pretraining'\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='val_loss',\n",
    "        dirpath=pretraining_path,\n",
    "        filename='pretraining-{epoch:02d}-{val_f1:.4f}',\n",
    "        save_top_k=1,\n",
    "        mode = 'min'\n",
    "    )\n",
    "\n",
    "    callbacks.append(checkpoint_callback)\n",
    "\n",
    "    trainer = Trainer(\n",
    "                    devices = n_gpus,\n",
    "                    accelerator=\"cuda\" if n_gpus >= 1 else 'cpu',\n",
    "                    # replace_sampler_ddp=False,\n",
    "                    max_epochs = max_epochs,\n",
    "                    num_sanity_val_steps = 2,\n",
    "                    callbacks = callbacks,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, pl_datamodule)\n",
    "    \n",
    "    pretraining_path = checkpoint_callback.best_model_path\n",
    "\n",
    "    model = model.load_from_checkpoint(pretraining_path)\n",
    "\n",
    "    model.do_finetuning()\n",
    "    \n",
    "        \n",
    "    train_ds = VIMERegressionDataset(X_train, y_train.values, data_hparams, X_unlabeled, continuous_cols, category_cols)\n",
    "    test_ds = VIMERegressionDataset(X_valid, y_valid.values, data_hparams, None, continuous_cols, category_cols)\n",
    "\n",
    "    pl_datamodule = PLDataModule(train_ds, test_ds, batch_size = batch_size, is_regression=True, n_jobs=1)\n",
    "        \n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor= 'val_' + metric, \n",
    "            mode = 'max',\n",
    "            patience = early_stopping_patience,\n",
    "            verbose = False\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    checkpoint_path = None\n",
    "\n",
    "    checkpoint_path = f'temporary_ckpt_data/'\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='val_' + metric,\n",
    "        dirpath=checkpoint_path,\n",
    "        filename='{epoch:02d}-{val_f1:.4f}',\n",
    "        save_top_k=1,\n",
    "        mode = 'max'\n",
    "    )\n",
    "\n",
    "    callbacks.append(checkpoint_callback)\n",
    "\n",
    "    trainer = Trainer(\n",
    "                    devices = n_gpus,\n",
    "                    accelerator = \"cuda\" if n_gpus >= 1 else 'cpu',\n",
    "                    # replace_sampler_ddp=False,\n",
    "                    max_epochs = max_epochs,\n",
    "                    num_sanity_val_steps = 2,\n",
    "                    callbacks = callbacks,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, pl_datamodule)\n",
    "\n",
    "    model = model.load_from_checkpoint(checkpoint_callback.best_model_path)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/opt/conda/envs/py37/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /workspace/vime/temporary_ckpt_data/pretraining exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name                      | Type             | Params\n",
      "---------------------------------------------------------------\n",
      "0 | model                     | VIME             | 70.5 K\n",
      "1 | pretraining_mask_loss     | BCELoss          | 0     \n",
      "2 | pretraining_feature_loss1 | CrossEntropyLoss | 0     \n",
      "3 | pretraining_feature_loss2 | MSELoss          | 0     \n",
      "4 | consistency_loss          | MSELoss          | 0     \n",
      "5 | loss_fn                   | MSELoss          | 0     \n",
      "---------------------------------------------------------------\n",
      "70.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "70.5 K    Total params\n",
      "0.282     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f828720e4dbe4ca0b0e820dd4b4fb28d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py37/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1613: PossibleUserWarning: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2481287ebb24b7db17601a53391cf4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c955fe3f9d46c694c97983e53010de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559782a908024df99ebd6efa4c0928bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfaf73863557475c9be8c09105f74427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09545c4ff8ef4405a9f62d3751255c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bddaaca188b5415cbca484186a701612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ef8c1274fd46d1b931d7206bc49c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "927a819ce1a643e7be3263fa17ff86cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fd5340fad834568950275ab70012518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf99ffc479c495e93d085b832b9e20b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3f64d3a91d4600aa85bb557334b39a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Global seed set to 0\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/opt/conda/envs/py37/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /workspace/vime/temporary_ckpt_data exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name                      | Type             | Params\n",
      "---------------------------------------------------------------\n",
      "0 | model                     | VIME             | 70.5 K\n",
      "1 | pretraining_mask_loss     | BCELoss          | 0     \n",
      "2 | pretraining_feature_loss1 | CrossEntropyLoss | 0     \n",
      "3 | pretraining_feature_loss2 | MSELoss          | 0     \n",
      "4 | consistency_loss          | MSELoss          | 0     \n",
      "5 | loss_fn                   | MSELoss          | 0     \n",
      "---------------------------------------------------------------\n",
      "70.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "70.5 K    Total params\n",
      "0.282     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cbcbedcd975463bbb0c6d05e8b6f630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py37/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "/opt/conda/envs/py37/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "/opt/conda/envs/py37/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1613: PossibleUserWarning: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de666d5ec8534477b57561f2a936e814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([10, 1])) that is different to the input size (torch.Size([10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d90a8aba2a8b4aeeb913d40a5e016e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([10, 1])) that is different to the input size (torch.Size([10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0bb2d3470f642988927b390753df60f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([10, 1])) that is different to the input size (torch.Size([10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86a3bbeeaafb4e81a0222f00c7b490ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([10, 1])) that is different to the input size (torch.Size([10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425daee9e6c242c995b1f64401fe9840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([10, 1])) that is different to the input size (torch.Size([10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359a7b626b454a698143edf011f44aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([10, 1])) that is different to the input size (torch.Size([10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "820d3e26748f4c02ace03598604e8815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([10, 1])) that is different to the input size (torch.Size([10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c633c71ae90f4c85b10004c350ff037a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([10, 1])) that is different to the input size (torch.Size([10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3efa45755555458e800f50f102222307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([10, 1])) that is different to the input size (torch.Size([10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cac5b012735481fa7d3175897ce4192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([10, 1])) that is different to the input size (torch.Size([10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62829c0ec67443aa3d4da284f442cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Global seed set to 0\n"
     ]
    }
   ],
   "source": [
    "pl_vime = fit_model(pl_vime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "697fbe01723245a8bfadb8c94eaef5d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "                    devices = n_gpus,\n",
    "                    accelerator = \"cuda\" if n_gpus >= 1 else 'cpu',\n",
    "                    # replace_sampler_ddp=False,\n",
    "                    max_epochs = max_epochs,\n",
    "                    num_sanity_val_steps = 2,\n",
    "                    callbacks = None,\n",
    "    )\n",
    "test_ds = VIMERegressionDataset(X_valid, y_valid.values, data_hparams, None, continuous_cols, category_cols)\n",
    "test_dl = DataLoader(test_ds, batch_size, shuffle=False, sampler = SequentialSampler(test_ds), num_workers=n_jobs)\n",
    "\n",
    "pl_vime.do_finetuning()\n",
    "\n",
    "preds = trainer.predict(pl_vime, test_dl)\n",
    "\n",
    "preds = np.concatenate([out.cpu().numpy() for out in preds])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13981.019278119371"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_valid, preds.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pl_vime.do_finetuning()\n",
    "    preds = pl_vime(torch.from_numpy(X_valid.values).to(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = pl_vime.model.self_sl.h(torch.from_numpy(X_valid.values).to(torch.float32))\n",
    "    out = pl_vime.model.semi_sl(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
